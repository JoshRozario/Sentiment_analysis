{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sklearn\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "import nltk\r\n",
    "import string\r\n",
    "from nltk.tokenize import ToktokTokenizer\r\n",
    "import re \r\n",
    "import spacy\r\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(os.listdir(\"./input\"))\r\n",
    "\r\n",
    "imdb = pd.read_csv('./input/imdb_labelled.txt', sep ='\\t', header = None)\r\n",
    "\r\n",
    "imdb.columns = [\"sentence\",  \"sentiment\"]\r\n",
    "\r\n",
    "amazon = pd.read_csv('./input/amazon_cells_labelled.txt', sep ='\\t', header = None)\r\n",
    "\r\n",
    "amazon.columns = [\"sentence\",  \"sentiment\"]\r\n",
    "\r\n",
    "yelp = pd.read_csv('./input/yelp_labelled.txt', sep ='\\t', header = None)\r\n",
    "\r\n",
    "yelp.columns = [\"sentence\",  \"sentiment\"]\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['amazon_cells_labelled.txt', 'imdb_labelled.txt', 'yelp_labelled.txt']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Strip functions\r\n",
    "\r\n",
    "tokenizer = ToktokTokenizer()\r\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\r\n",
    "# custom: removing words from list\r\n",
    "stopword_list.remove('not')\r\n",
    "\r\n",
    "# call function\r\n",
    "\r\n",
    "def remove_punctuation(text):\r\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\r\n",
    "    return text\r\n",
    "\r\n",
    "# function to remove stopwords\r\n",
    "def remove_stopwords(text):\r\n",
    "    # convert sentence into token of words\r\n",
    "    tokens = tokenizer.tokenize(text)\r\n",
    "    tokens = [token.strip() for token in tokens]\r\n",
    "    # check in lowercase \r\n",
    "    t = [token for token in tokens if token.lower() not in stopword_list]\r\n",
    "    text = ' '.join(t)    \r\n",
    "    return text\r\n",
    "\r\n",
    "# function to remove special characters\r\n",
    "def remove_extra_whitespace_tabs(text):\r\n",
    "    #pattern = r'^\\s+$|\\s+$'\r\n",
    "    pattern = r'^\\s*|\\s\\s*'\r\n",
    "    return re.sub(pattern, ' ', text).strip()\r\n",
    "\r\n",
    "# function to remove special characters\r\n",
    "def to_lowercase(text):\r\n",
    "    return text.lower()\r\n",
    "\r\n",
    "# function to remove numbers\r\n",
    "def remove_numbers(text):\r\n",
    "    # define the pattern to keep\r\n",
    "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \r\n",
    "    return re.sub(pattern, '', text)\r\n",
    "\r\n",
    "nlp = spacy.load(\"en_core_web_sm\")\r\n",
    "\r\n",
    "# function to remove special characters\r\n",
    "def get_lem(text):\r\n",
    "    text = nlp(text)\r\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\r\n",
    "    return text\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\r\n",
    "\r\n",
    "X = imdb['sentence'].map(remove_extra_whitespace_tabs)\r\n",
    "X = X.map(remove_stopwords)\r\n",
    "X = X.map(get_lem)\r\n",
    "X = X.map(to_lowercase)\r\n",
    "\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer()\r\n",
    "X = X\r\n",
    "y = imdb['sentiment']\r\n",
    "X = tfidf.fit_transform(X)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\r\n",
    "\r\n",
    "clf = LinearSVC()\r\n",
    "\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = clf.predict(X_test)\r\n",
    "print(classification_report(y_test, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        84\n",
      "           1       0.69      0.94      0.79        66\n",
      "\n",
      "    accuracy                           0.79       150\n",
      "   macro avg       0.81      0.80      0.79       150\n",
      "weighted avg       0.83      0.79      0.79       150\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\r\n",
    "\r\n",
    "X = amazon['sentence'].map(remove_extra_whitespace_tabs)\r\n",
    "X = X.map(remove_stopwords)\r\n",
    "#X = X.map(remove_punctuation)\r\n",
    "X = X.map(to_lowercase)\r\n",
    "\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer(ngram_range = (1,4))\r\n",
    "X = X\r\n",
    "y = amazon['sentiment']\r\n",
    "X = tfidf.fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\r\n",
    "\r\n",
    "clf = LinearSVC(C=10)\r\n",
    "\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = clf.predict(X_test)\r\n",
    "print(classification_report(y_test, y_pred))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85        97\n",
      "           1       0.88      0.83      0.85       103\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.85      0.85      0.85       200\n",
      "weighted avg       0.85      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\r\n",
    "\r\n",
    "X = yelp['sentence'].map(remove_extra_whitespace_tabs)\r\n",
    "X = X.map(remove_punctuation)\r\n",
    "#X = X.map(remove_stopwords)\r\n",
    "X = X.map(get_lem)\r\n",
    "X = X.map(to_lowercase)\r\n",
    "\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer()\r\n",
    "X = X\r\n",
    "y = yelp['sentiment']\r\n",
    "X = tfidf.fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\r\n",
    "\r\n",
    "clf = LinearSVC()\r\n",
    "\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "y_pred = clf.predict(X_test)\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85        97\n",
      "           1       0.88      0.83      0.85       103\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.85      0.85      0.85       200\n",
      "weighted avg       0.85      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Set the parameters by cross-validation\r\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\r\n",
    "                     'C': [1, 10, 100, 1000]},\r\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\r\n",
    "                    {'kernel': ['poly'], 'gamma': [1e-3, 1e-4],\r\n",
    "                     'C': [1, 10, 100, 1000]},]\r\n",
    "\r\n",
    "print(sklearn.metrics.SCORERS.keys())\r\n",
    "\r\n",
    "scores = ['f1']\r\n",
    "\r\n",
    "for score in scores:\r\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\r\n",
    "    print()\r\n",
    "\r\n",
    "    clf = GridSearchCV(\r\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\r\n",
    "    )\r\n",
    "    clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "    print(\"Best parameters set found on development set:\")\r\n",
    "    print()\r\n",
    "    print(clf.best_params_)\r\n",
    "    print()\r\n",
    "    print(\"Grid scores on development set:\")\r\n",
    "    print()\r\n",
    "    means = clf.cv_results_['mean_test_score']\r\n",
    "    stds = clf.cv_results_['std_test_score']\r\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\r\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\r\n",
    "              % (mean, std * 2, params))\r\n",
    "    print()\r\n",
    "\r\n",
    "    print(\"Detailed classification report:\")\r\n",
    "    print()\r\n",
    "    print(\"The model is trained on the full development set.\")\r\n",
    "    print(\"The scores are computed on the full evaluation set.\")\r\n",
    "    print()\r\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\r\n",
    "    print(classification_report(y_true, y_pred))\r\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.335 (+/-0.003) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.335 (+/-0.003) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.335 (+/-0.003) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.335 (+/-0.003) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.799 (+/-0.088) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.335 (+/-0.003) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.802 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.799 (+/-0.088) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.802 (+/-0.091) for {'C': 1, 'kernel': 'linear'}\n",
      "0.807 (+/-0.049) for {'C': 10, 'kernel': 'linear'}\n",
      "0.806 (+/-0.045) for {'C': 100, 'kernel': 'linear'}\n",
      "0.806 (+/-0.045) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.335 (+/-0.003) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.335 (+/-0.003) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        97\n",
      "           1       0.83      0.81      0.82       103\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.82      0.81       200\n",
      "weighted avg       0.82      0.81      0.82       200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}